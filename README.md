# J.A.R.V.I.S â€“ Local Voice Assistant

Jarvis is a **fully local voice assistant** that combines:
- ðŸŽ¤ **Whisper.cpp** for speech-to-text (STT)
- ðŸ§  **Llama.cpp** for natural language processing (LLM)
- ðŸ”Š **Piper** for text-to-speech (TTS)
- ðŸ‘‚ **OpenWakeWord** for wake word detection ("Hey Jarvis")

âš¡ Everything runs **offline** â€” no internet is required for processing.  
Jarvis is designed to be modular, hackable, and extendable to control smart devices or even robots.

---

## âœ¨ Features (Current Progress)

âœ… **Wake Word ("Hey Jarvis")**  
- Powered by [OpenWakeWord](https://github.com/dscripka/openWakeWord?tab=readme-ov-file)  
- Starts listening only after hearing the wake phrase  

âœ… **Speech-to-Text (STT)**  
- Uses `sounddevice` + `webrtcvad` for smart recording (stops when you go quiet)  
- Transcribes audio with `whisper-cli` (from Whisper.cpp)  

âœ… **Local Language Model (LLM)**  
- Runs `llama.cpp` in server mode  
- Configurable system prompt â†’ "Jarvis"-like personality  

âœ… **Text-to-Speech (TTS)**  
- Piper HTTP server generates natural-sounding voices  
- Multiple voices available (e.g., `en_US-bryce-medium`)  

âœ… **Main Pipeline**  
Wake Word â†’ Record â†’ Transcribe â†’ Send to LLM â†’ Speak Response

âœ… **Benchmarking**  
- `benchmark_ai.sh` logs timings for STT, LLM, and TTS  
- Results are stored in `latency.md`  

âœ… **CI / Mock Mode**  
- GitHub Actions run Jarvis in **Mock Mode** (no audio hardware required)  
- Simulates STT, LLM, and TTS responses for automated testing  

---

## ðŸš€ Getting Started

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

Also build:
- Whisper.cpp
- Llama.cpp
- Piper


### 2. Start LLM + TTS servers
```bash
./scripts/run_servers.sh
```

Say "Hey Jarvis", wait for the beep ðŸŽµ, then speak your command.
Jarvis will listen, process locally, and respond with speech.

